{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P-values in ML 02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import scipy as sc\n",
    "import sklearn as sk\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from scipy.stats import chi2\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from statsmodels.discrete.discrete_model import Logit\n",
    "from statsmodels.stats.multitest import fdrcorrection\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit(h):\n",
    "    ''' Logistic from activation h '''\n",
    "    p = 1.0 / (1.0 + np.exp(-h))\n",
    "    r = np.random.rand(len(p))\n",
    "    y = (r < p).astype('float')\n",
    "    return y\n",
    "\n",
    "\n",
    "def rand_date():\n",
    "    max_time = int(time.time())\n",
    "    t = random.randint(0, max_time)\n",
    "    return time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(t))\n",
    "\n",
    "\n",
    "def rand_unif(num, mean, std, na_prob=0):\n",
    "    xi = np.random.rand(num)\n",
    "    if na_prob > 0:\n",
    "        xi_na = (np.random.rand(num) <= na_prob)\n",
    "        xi[xi_na] = np.nan\n",
    "    return xi\n",
    "\n",
    "\n",
    "def rand_norm(num, mean=0.0, std=1.0, na_prob=0):\n",
    "    xi = np.random.normal(mean, std, num)\n",
    "    if na_prob > 0:\n",
    "        xi_na = (np.random.rand(num) <= na_prob)\n",
    "        xi[xi_na] = np.nan\n",
    "    return xi\n",
    "\n",
    "\n",
    "def rbf(x, mu=0, sigma=1):\n",
    "    \"\"\" Radial basis function \"\"\"\n",
    "    z = (x - mu) / sigma\n",
    "    return np.exp(-(z*z))\n",
    "\n",
    "\n",
    "def split_df(df, var_inputs, var_output, train_index, val_index):\n",
    "    df_train, df_val = df.iloc[train_index], df.iloc[val_index]\n",
    "    return df_train[var_inputs], df_train[var_output], df_val[var_inputs], df_val[var_output]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_01(num=1000, save=False):\n",
    "    \"\"\" Create dataset y = f(x1, x2, x3) + noise (r* are not used) \"\"\"\n",
    "    x1 = rand_norm(num)\n",
    "    x2 = rand_norm(num)\n",
    "    x3 = rand_norm(num)\n",
    "    x4 = rand_norm(num)\n",
    "    x5 = rand_norm(num)\n",
    "    n = rand_norm(num)\n",
    "    y = logit(3.0 * x1 - 2.0 * x2 + 1.0 * x3 + 0.5 * n)\n",
    "    df = pd.DataFrame({'x1': x1, 'x2': x2, 'x3': x3, 'x4': x4, 'x5': x5, 'y': y})\n",
    "    if save:\n",
    "        file = 'zzz.csv'\n",
    "        print(f\"Saving dataset to file '{file}'\")\n",
    "        df.to_csv(file, index=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_02(num=1000, save=False):\n",
    "    \"\"\" Create dataset y = f(x1, x2, x3) + noise (r* are not used) \"\"\"\n",
    "    x1 = rand_norm(num)\n",
    "    x2 = rand_norm(num)\n",
    "    x3 = rand_norm(num)\n",
    "    x4 = rand_norm(num)\n",
    "    x5 = rand_norm(num)\n",
    "    n = rand_norm(num)\n",
    "    y = logit(0.5 * rbf(x1, 1, 1) - 0.3 * rbf(x2, -1, 1) + 0.3 * x3 + 0.5 * n)\n",
    "    df = pd.DataFrame({'x1': x1, 'x2': x2, 'x3': x3, 'x4': x4, 'x5': x5, 'y': y})\n",
    "    if save:\n",
    "        file = 'zzz.csv'\n",
    "        print(f\"Saving dataset to file '{file}'\")\n",
    "        df.to_csv(file, index=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importance: Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wilks_model_fit(x, y):\n",
    "    logit_model = Logit(y, x)\n",
    "    res = logit_model.fit(disp=0)\n",
    "    return logit_model, res\n",
    "\n",
    "def wilks_p_value(df, var_output, vars_null):\n",
    "    model_null, model_null_results = wilks_model_fit(df[vars_null], df[var_output])\n",
    "    pvalues = dict()\n",
    "    for c in df.columns:\n",
    "        if c != var_output and c not in vars_null:\n",
    "            xnames = list(vars_null)\n",
    "            xnames.append(c)\n",
    "            model_alt, model_alt_res = wilks_model_fit(df[xnames], df[var_output])\n",
    "            if model_alt is None:\n",
    "                self._error(f\"Could not fit alt model for column/s {c}\")\n",
    "                pval = 1.0\n",
    "            else:\n",
    "                d = 2.0 * (model_alt_res.llf - model_null_results.llf)\n",
    "                pval = chi2.sf(d, 1)\n",
    "            pvalues[c] = pval\n",
    "    return pd.Series(pvalues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importance: ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validations & models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "def new_model_fit(x_train, y_train):\n",
    "    model = RandomForestClassifier(100)\n",
    "    model.fit(x_train, y_train)\n",
    "    return model\n",
    "\n",
    "_id = 0\n",
    "def next_id():\n",
    "    global _id\n",
    "    _id += 1\n",
    "    return _id\n",
    "\n",
    "\n",
    "def is_var_rand(var):\n",
    "    return var is not None and var.startswith('__rand_')\n",
    "\n",
    "\n",
    "class FeatureImportanceShuffle:\n",
    "    \"\"\" Feature importance by shuffling input values \"\"\"\n",
    "    def __init__(self, model, x_train, y_train, x_val, y_val, num_iter=10):\n",
    "        self.id = next_id()\n",
    "        self.model = model\n",
    "        self.x_train, self.y_train, self.x_val, self.y_val = x_train, y_train, x_val, y_val\n",
    "        self.num_iter = num_iter\n",
    "        self.score_null = None  # Null score (one score)\n",
    "        self.scores_alt = dict()  # Alt scores by variable name (multiple scores for each variable)\n",
    "\n",
    "    def add_score(self, var, score):\n",
    "        \"\"\" Add score for variable 'var' \"\"\"\n",
    "        if var not in self.scores_alt:\n",
    "            self.scores_alt[var] = list()\n",
    "        self.scores_alt[var].append(score)\n",
    "\n",
    "    def __call__(self):\n",
    "        \"\"\" Feature importance by shuffling variable 'var' and comparing performance results \"\"\"\n",
    "        if not self.score_null:\n",
    "            self.score_null = self.model.score(self.x_val, self.y_val)\n",
    "            # print(f\"\\t\\tFeature importance (id={self.id}): Null model {self.scores_null}\")\n",
    "        for var in self.x_train.columns:\n",
    "            # Perform shuffling 'num_iter' times\n",
    "            scores = list()\n",
    "            for i in range(self.num_iter):\n",
    "                score = self.feature_importance_variable(var)\n",
    "                scores.append(score)\n",
    "                self.add_score(var, score)\n",
    "            scores = np.array(scores)\n",
    "            # print(f\"\\t{var}:\\tcount: {len(scores)}\\tmean: {scores.mean()}\\tstd: {scores.std()}\")\n",
    "\n",
    "    def feature_importance_variable(self, var):\n",
    "        \"\"\" Feature importance by shuffling variable 'var' and comparing performance results \"\"\"\n",
    "        # Shuffle 'var' and calculate validation score\n",
    "        x_shuf = self.x_val.copy()\n",
    "        x_shuf[var] = x_shuf[var].sample(frac=1).values\n",
    "        score = self.model.score(x_shuf, self.y_val)\n",
    "        # print(f\"\\t\\tFeature importance (id={self.id}): Variable '{var}, score: {score}'\")\n",
    "        return score\n",
    "\n",
    "    def get_null(self):\n",
    "        \"\"\" Get null score \"\"\"\n",
    "        return self.score_null\n",
    "\n",
    "    def get_null_and_rand(self, exclude_var=None):\n",
    "        \"\"\" Get null and all '__rand_' scores as a list \"\"\"\n",
    "        values = [self.score_null]\n",
    "        for var in self.x_train.columns:\n",
    "            if is_var_rand(var) and var != exclude_var:\n",
    "                values.extend(self.scores_alt[var])\n",
    "        return values\n",
    "\n",
    "    def get_alt(self, var):\n",
    "        \"\"\" Get scores for variable 'var', or None if not found \"\"\"\n",
    "        return self.scores_alt.get(var)\n",
    "\n",
    "\n",
    "class FeatureImportance:\n",
    "    \"\"\"\n",
    "    Calculate feature importance.\n",
    "    \"\"\"\n",
    "    def __init__(self, df, var_output, vars_input=None, vars_null=None, new_model_function=new_model_fit, num_cv=5, num_shuffle=10, num_rand=5, max_iter=10):\n",
    "        self.df_ori = df\n",
    "        self.var_output, self.vars_input, self.vars_null = var_output, vars_input, vars_null\n",
    "        if self.vars_input is None:\n",
    "            self.vars_input = [c for c in df.columns if c != var_output]\n",
    "        if self.vars_null is None:\n",
    "            self.vars_null = [c for c in self.vars_input if c.startswith('rand_')]\n",
    "        self.new_model_function = new_model_function\n",
    "        self.df = None\n",
    "        self.pvals_df = None\n",
    "        self.max_iter =max_iter\n",
    "        self.num_cv = num_cv\n",
    "        self.num_rand = num_rand\n",
    "        self.num_shuffle = num_shuffle\n",
    "        self.cvs = list()  # List of cross validation items\n",
    "    \n",
    "    def __call__(self):\n",
    "        # initialize\n",
    "        self.df = self.extend_df_ori()\n",
    "        self.initialize_cv()\n",
    "        # Calculate importance by shuffling\n",
    "        for count_iter in range(self.max_iter):\n",
    "            self.pvals_df = pd.DataFrame()\n",
    "            for fis in self.cvs:\n",
    "                print(f\"Iteration: {count_iter}, Cross-validation: {fis.id}\")\n",
    "                fis()\n",
    "            stop = self.p_values()\n",
    "            if stop:\n",
    "                return self.pvals_df\n",
    "        return self.pvals_df\n",
    "    \n",
    "    def cv_iter(self, df):\n",
    "        \"\"\" Create a cross-validation iterator \"\"\"\n",
    "        if self.num_cv > 1:\n",
    "            return KFold(n_splits=self.num_cv).split(df)\n",
    "        else:\n",
    "            # No cross validation, split 80% / 20%\n",
    "            idx = int(0.8 * len(df))\n",
    "            idx_train = range(0, idx)\n",
    "            idx_val = range(idx, len(df))\n",
    "            return [(idx_train, idx_val)]\n",
    "        \n",
    "    def extend_df_ori(self):\n",
    "        \"\"\" Extend the data frame by adding random permutations and random variables \"\"\"\n",
    "        df = self.df_ori.copy()\n",
    "        # Create one additional 'rand' column for every variable\n",
    "        for c in self.df_ori.columns:\n",
    "            c_rand = f\"__rand_{c}\"\n",
    "            self.vars_input.append(c_rand)\n",
    "            df[c_rand] = df[c].sample(frac=1).values\n",
    "        # Create one additional 'rand' column for every variable\n",
    "        for i in range(self.num_rand):\n",
    "            c_rand = f\"__rand_{i}\"\n",
    "            self.vars_input.append(c_rand)\n",
    "            df[c_rand] = np.random.rand(len(df[c]))\n",
    "        return df\n",
    "        \n",
    "    def get_alts(self, var):\n",
    "        \"\"\" Get alt scores for variable 'var' \"\"\"\n",
    "        scores = list()\n",
    "        for fis in self.cvs:\n",
    "            ss = fis.get_alt(var)\n",
    "            if ss is not None:\n",
    "                scores.extend(ss)\n",
    "        return np.array(scores)\n",
    "\n",
    "    def get_nulls(self, var):\n",
    "        \"\"\" Get null scores, excluding variable 'var' \"\"\"\n",
    "        scores = list()\n",
    "        for fis in self.cvs:\n",
    "            ss = fis.get_null_and_rand(exclude_var=var)\n",
    "            if ss is not None:\n",
    "                scores.extend(ss)\n",
    "        return np.array(scores)\n",
    "\n",
    "    def initialize_cv(self):\n",
    "        \"\"\" Initialize cross validations \"\"\"\n",
    "        for train_index, val_index in self.cv_iter(self.df):\n",
    "            x_train, y_train, x_validate, y_validate = split_df(self.df, self.vars_input, self.var_output, train_index, val_index)\n",
    "            model = self.new_model_function(x_train, y_train)\n",
    "            fis = FeatureImportanceShuffle(model, x_train, y_train, x_validate, y_validate, num_iter=self.num_shuffle)\n",
    "            self.cvs.append(fis)\n",
    "\n",
    "    def p_value(self, var, null_scores, alt_scores):\n",
    "        null_scores, alt_scores = np.array(null_scores), np.array(alt_scores)\n",
    "        pval = sc.stats.mannwhitneyu(null_scores, alt_scores, alternative='greater')[1]\n",
    "        df_row = pd.DataFrame({'name': var\n",
    "                               , 'count_alt': len(alt_scores)\n",
    "                               , 'mean_alt': alt_scores.mean()\n",
    "                               , 'std_alt': alt_scores.std()\n",
    "                               , 'count_null': len(null_scores)\n",
    "                               , 'mean_null': null_scores.mean()\n",
    "                               , 'std_null': null_scores.std()\n",
    "                               , 'p_value': pval}, index=[len(self.pvals_df)])\n",
    "        self.pvals_df = self.pvals_df.append(df_row)\n",
    "        return pval\n",
    "\n",
    "    def p_values(self):\n",
    "        # Get null scores\n",
    "        null_scores = list()\n",
    "        for fis in self.cvs:\n",
    "            null_scores.extend(fis.get_null_and_rand())\n",
    "        # Calculate p-value for every variable\n",
    "        pvals, isrand = list(), list()\n",
    "        for var in self.vars_input:\n",
    "            alt_scores = self.get_alts(var)\n",
    "            null_scores = self.get_nulls(var)\n",
    "            pval = self.p_value(var, null_scores, alt_scores)\n",
    "            pvals.append(pval)\n",
    "            isrand.append(is_var_rand(var))\n",
    "        pvals = np.array(pvals)\n",
    "        isrand = np.array(isrand)\n",
    "        rejected, pvals_fdr = fdrcorrection(pvals)\n",
    "        self.pvals_df['pvalues_fdr'] = pvals_fdr\n",
    "        self.pvals_df['pvalues_fdr_reject'] = rejected\n",
    "        return (rejected & isrand).any()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### P-values analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# def pvalues_shuffle_analysis():\n",
    "#     pvals_df = None\n",
    "#     for num_cv in [1, 3, 5, 10, 20]:\n",
    "#         for num_samples in [50, 100, 200, 300, 400, 500, 1000, 2000, 10000]:\n",
    "#             for num_shuffle in [3, 5, 10, 20, 50, 100]:\n",
    "#                 pvals_df = p_values_shuffle(num_samples=num_samples, n_rands=5, num_cv=num_cv, num_shuffle=num_shuffle, pvals_df=pvals_df)\n",
    "#                 print(f\"num_cv: {num_cv}\\tnum_samples:{num_samples}\\tnum_shuffle:{num_shuffle}\")\n",
    "#     pvals_df.to_csv('p_values_shuffle.csv')\n",
    "#     return pvals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.382666</td>\n",
       "      <td>-0.348815</td>\n",
       "      <td>0.280558</td>\n",
       "      <td>0.494661</td>\n",
       "      <td>-0.745136</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.755279</td>\n",
       "      <td>1.390585</td>\n",
       "      <td>-1.011255</td>\n",
       "      <td>-0.818307</td>\n",
       "      <td>0.330761</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.167847</td>\n",
       "      <td>0.398118</td>\n",
       "      <td>-0.206344</td>\n",
       "      <td>0.901032</td>\n",
       "      <td>-1.967521</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.558598</td>\n",
       "      <td>0.091097</td>\n",
       "      <td>0.182158</td>\n",
       "      <td>-0.821111</td>\n",
       "      <td>-0.200976</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.111655</td>\n",
       "      <td>0.118912</td>\n",
       "      <td>1.154168</td>\n",
       "      <td>1.323366</td>\n",
       "      <td>-0.379509</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         x1        x2        x3        x4        x5    y\n",
       "0  0.382666 -0.348815  0.280558  0.494661 -0.745136  1.0\n",
       "1 -0.755279  1.390585 -1.011255 -0.818307  0.330761  1.0\n",
       "2 -0.167847  0.398118 -0.206344  0.901032 -1.967521  0.0\n",
       "3  0.558598  0.091097  0.182158 -0.821111 -0.200976  1.0\n",
       "4  1.111655  0.118912  1.154168  1.323366 -0.379509  1.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_samples = 10000\n",
    "df = create_dataset_02(num_samples)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0, Cross-validation: 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-0b4d2a243feb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFeatureImportance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'y'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_shuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_cv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mnew_model_function\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_model_fit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-3eda88031c40>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mfis\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Iteration: {count_iter}, Cross-validation: {fis.id}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m                 \u001b[0mfis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m             \u001b[0mstop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-3eda88031c40>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m                 \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importance_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m                 \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-3eda88031c40>\u001b[0m in \u001b[0;36mfeature_importance_variable\u001b[0;34m(self, var)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mx_shuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mx_shuf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_shuf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrac\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_shuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0;31m# print(f\"\\t\\tFeature importance (id={self.id}): Variable '{var}, score: {score}'\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mlgen/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    355\u001b[0m         \"\"\"\n\u001b[1;32m    356\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mlgen/lib/python3.7/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \"\"\"\n\u001b[0;32m--> 545\u001b[0;31m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mlgen/lib/python3.7/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    599\u001b[0m             delayed(_accumulate_prediction)(e.predict_proba, X, all_proba,\n\u001b[1;32m    600\u001b[0m                                             lock)\n\u001b[0;32m--> 601\u001b[0;31m             for e in self.estimators_)\n\u001b[0m\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mproba\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_proba\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mlgen/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1004\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1006\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1007\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mlgen/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 834\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    835\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mlgen/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    751\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 753\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    754\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mlgen/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mlgen/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    580\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 582\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mlgen/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mlgen/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mlgen/lib/python3.7/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36m_accumulate_prediction\u001b[0;34m(predict, X, out, lock)\u001b[0m\n\u001b[1;32m    392\u001b[0m     \u001b[0mcomplains\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mit\u001b[0m \u001b[0mcannot\u001b[0m \u001b[0mpickle\u001b[0m \u001b[0mit\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0mplaced\u001b[0m \u001b[0mthere\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m     \"\"\"\n\u001b[0;32m--> 394\u001b[0;31m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mlgen/lib/python3.7/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    846\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tree_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fi = FeatureImportance(df, 'y', num_shuffle=20, num_cv=10 ,new_model_function=new_model_fit)\n",
    "fi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlgen",
   "language": "python",
   "name": "mlgen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
